import streamlit as st
import time
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from scipy.stats import norm
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.cluster import KMeans

# è®¾ç½®é¡µé¢ä¸ºå®½å±æ¨¡å¼
st.set_page_config(layout="wide")


# å®šä¹‰ä¸åŒçš„å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å°†åœ¨é€‰æ‹©å¯¹åº”é€‰é¡¹æ—¶æ‰§è¡Œ
def function1():
    st.write(" Executed> ğŸ‘©â€ğŸ’»**Database Version:** Bump Test: V0")

    # åŠ è½½æ•°æ®å¹¶è¿›è¡Œè½¬ç½®
    @st.cache_data
    def load_data():
        data = pd.read_csv('knc_bump_data_v01.csv')
        # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯åˆ—åï¼Œç¬¬ä¸€åˆ—æ˜¯è½¦å‹ï¼Œè¿›è¡Œè½¬ç½®
        data = data.set_index(data.columns[0]).transpose()
        return data
    

    df_bump = load_data()

    # Streamlit é¡µé¢è®¾ç½®
    #st.title('KnC Database Analysis')

    filename = 'knc_bump_data_v01.csv'
    st.write("Loaded Filename:")
    st.text(filename)

    # ä½¿ç”¨ multiselect é€‰æ‹©è¦åˆ†æçš„åˆ—
    selected_columns = st.multiselect('Select the columns for analysis:', df_bump.columns)

    # é€‰æ‹©åˆ†æç±»å‹
    analysis_type = st.radio(
        "Select the analysis type:",
        ('Normal Distribution Fit', 'K-means Clustering')
    )

    # æ ¹æ®é€‰æ‹©è¿›è¡Œåˆ†æ
    if analysis_type == 'Normal Distribution Fit':
        for selected_column in selected_columns:
            # å¯¹é€‰å®šçš„åˆ—è¿›è¡Œæ­£æ€åˆ†å¸ƒæ‹Ÿåˆ
            data = df_bump[selected_column].dropna()
            mu, std = norm.fit(data)
            
            # æ¯ä¸ªåˆ—éƒ½æ–°å»ºä¸€ä¸ªå›¾å½¢
            fig, ax = plt.subplots()
            ax.hist(data, bins=30, density=True, alpha=0.6, color='g')
            xmin, xmax = ax.get_xlim()
            x = np.linspace(xmin, xmax, 100)
            p = norm.pdf(x, mu, std)
            ax.plot(x, p, 'k', linewidth=2)
            ax.set_title(f'Normal Distribution Fit for {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Density')
            
            # æ˜¾ç¤ºå›¾å½¢
            st.pyplot(fig)
            
            # å…³é—­å›¾å½¢ä»¥é¿å…é‡å 
            plt.close(fig)

            with st.expander("Show Parameters"):
                st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                st.write("""
                    - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                    - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                    - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                    - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                """)

    elif analysis_type == 'K-means Clustering':
        # é€‰æ‹©è¦åˆ›å»ºçš„èšç±»æ•°
        num_clusters = st.slider('Select number of clusters:', min_value=2, max_value=10, value=3)

        if st.button('Perform K-means Clustering'):
            

            data = df_bump[selected_columns].dropna()
            kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data)
            df_bump['Cluster'] = kmeans.labels_

             # åœ¨è¿™é‡Œè®¡ç®—è¯„ä¼°æŒ‡æ ‡
            silhouette_avg = silhouette_score(data, kmeans.labels_)
            davies_bouldin = davies_bouldin_score(data, kmeans.labels_)
            calinski_harabasz = calinski_harabasz_score(data, kmeans.labels_)
            # å±•ç¤ºè¯„ä¼°æŒ‡æ ‡
            st.write(f"Silhouette Coefficient: {silhouette_avg}")
            st.write(f"Davies-Bouldin Index: {davies_bouldin}")
            st.write(f"Calinski-Harabasz Index: {calinski_harabasz}")
            # å¯æŠ˜å çš„è§£é‡Šéƒ¨åˆ†
            with st.expander("Explanation of Cluster Evaluation Metrics"):
                st.write("""
                    - **Silhouette Coefficient:** This metric ranges from -1 to 1. A high value indicates that objects are well matched to their own cluster and poorly matched to neighboring clusters.
                    - **Davies-Bouldin Index:** A lower index signifies a better partitioning. It is the average 'similarity' between clusters, where similarity is a measure that compares the distance between clusters with the size of the clusters themselves.
                    - **Calinski-Harabasz Index:** Also known as the Variance Ratio Criterion, a higher index relates to a model with better defined clusters.
                """)        

            # åˆ†åˆ—æ˜¾ç¤ºæ¯ä¸ªèšç±»çš„ç»Ÿè®¡ä¿¡æ¯
            cols = st.columns(num_clusters)
            max_num_cars = 0
            for i in range(num_clusters):
                cluster_data = df_bump[df_bump['Cluster'] == i]
                max_num_cars = max(max_num_cars, cluster_data.shape[0])
            
            for i in range(num_clusters):
                cluster_data = df_bump[df_bump['Cluster'] == i]
                with cols[i]:
                    st.write(f'Cluster {i+1}')
                    cluster_data_column = cluster_data[selected_columns]
                    # ä½¿ç”¨ Pandas çš„ describe æ–¹æ³•è®¡ç®—ç»Ÿè®¡æ•°æ®
                    st.dataframe(cluster_data_column.describe().transpose())

                    # è·å¾—å¹¶æ˜¾ç¤ºè½¦å‹æ•°æ®
                    car_types = cluster_data.index.unique()
                    car_types_df = pd.DataFrame(car_types, columns=['Car Type'])
                    # ä½¿è¡¨æ ¼çš„è¡Œæ•°ç›¸ç­‰
                    car_types_df = car_types_df.reindex(np.arange(max_num_cars)).fillna('')
                    st.dataframe(car_types_df)  # æ˜¾ç¤ºè½¦å‹è¡¨æ ¼


                    # ç»˜å›¾
                    for selected_column in selected_columns:
                        mu, std = norm.fit(cluster_data[selected_column])
                        plt.hist(cluster_data[selected_column], bins=30, density=True, alpha=0.6, color='g')
                        xmin, xmax = plt.xlim()
                        x = np.linspace(xmin, xmax, 100)
                        p = norm.pdf(x, mu, std)
                        plt.plot(x, p, 'k', linewidth=2)
                        plt.title(f'Normal Distribution for {selected_column}')
                        st.pyplot(plt)
                        plt.clf()  # æ¸…é™¤å›¾å½¢ä»¥å¤‡ä¸‹æ¬¡ç»˜åˆ¶

                        with st.expander("Show Parameters"):
                            st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                            st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                            st.write("""
                                - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                                - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                                - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                                - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                            """)
def function2():
    st.write(" Executed> ğŸ‘©â€ğŸ’»**Database Version:** Roll Test: V0")

    # åŠ è½½æ•°æ®å¹¶è¿›è¡Œè½¬ç½®
    @st.cache_data
    def load_data():
        data = pd.read_csv('knc_Roll_data_v01.csv')
        # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯åˆ—åï¼Œç¬¬ä¸€åˆ—æ˜¯è½¦å‹ï¼Œè¿›è¡Œè½¬ç½®
        data = data.set_index(data.columns[0]).transpose()
        return data
    

    df_roll = load_data()


    # åœ¨ Streamlit ä¸­æ˜¾ç¤ºæ–‡ä»¶å
    filename = 'knc_roll_data_v01.csv'
    st.write("Loaded Filename:")
    st.text(filename)

    # ä½¿ç”¨ multiselect é€‰æ‹©è¦åˆ†æçš„åˆ—
    selected_columns = st.multiselect('Select the columns for analysis:', df_roll.columns)

    # é€‰æ‹©åˆ†æç±»å‹
    analysis_type = st.radio(
        "Select the analysis type:",
        ('Normal Distribution Fit', 'K-means Clustering')
    )

    # æ ¹æ®é€‰æ‹©è¿›è¡Œåˆ†æ
    if analysis_type == 'Normal Distribution Fit':
        for selected_column in selected_columns:
            # å¯¹é€‰å®šçš„åˆ—è¿›è¡Œæ­£æ€åˆ†å¸ƒæ‹Ÿåˆ
            data = df_roll[selected_column].dropna()
            mu, std = norm.fit(data)
            
            # æ¯ä¸ªåˆ—éƒ½æ–°å»ºä¸€ä¸ªå›¾å½¢
            fig, ax = plt.subplots()
            ax.hist(data, bins=30, density=True, alpha=0.6, color='g')
            xmin, xmax = ax.get_xlim()
            x = np.linspace(xmin, xmax, 100)
            p = norm.pdf(x, mu, std)
            ax.plot(x, p, 'k', linewidth=2)
            ax.set_title(f'Normal Distribution Fit for {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Density')
            
            # æ˜¾ç¤ºå›¾å½¢
            st.pyplot(fig)
            
            # å…³é—­å›¾å½¢ä»¥é¿å…é‡å 
            plt.close(fig)

            with st.expander("Show Parameters"):
                st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                st.write("""
                    - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                    - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                    - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                    - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                """)

    elif analysis_type == 'K-means Clustering':
        # é€‰æ‹©è¦åˆ›å»ºçš„èšç±»æ•°
        num_clusters = st.slider('Select number of clusters:', min_value=2, max_value=10, value=3)

        if st.button('Perform K-means Clustering'):
            
            # Prepare the data by dropping NaNs and storing it for clustering
            data_for_clustering = df_roll[selected_columns].dropna()

            # Perform K-means Clustering
            kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data_for_clustering)

            # Create a new DataFrame for the cluster labels with the same index as the data used for clustering
            labels_df = pd.DataFrame(kmeans.labels_, index=data_for_clustering.index, columns=['Cluster'])

            # Join the cluster labels to the original DataFrame
            df_roll = df_roll.join(labels_df)

            # Compute the evaluation metrics
            silhouette_avg = silhouette_score(data_for_clustering, kmeans.labels_)
            davies_bouldin = davies_bouldin_score(data_for_clustering, kmeans.labels_)
            calinski_harabasz = calinski_harabasz_score(data_for_clustering, kmeans.labels_)
            # Display the evaluation metrics
            st.write(f"Silhouette Coefficient: {silhouette_avg}")
            st.write(f"Davies-Bouldin Index: {davies_bouldin}")
            st.write(f"Calinski-Harabasz Index: {calinski_harabasz}")
            # Expander for explanation of cluster evaluation metrics
            with st.expander("Explanation of Cluster Evaluation Metrics"):
                st.write("""
                    - **Silhouette Coefficient:** This metric ranges from -1 to 1. A high value indicates that objects are well matched to their own cluster and poorly matched to neighboring clusters.
                    - **Davies-Bouldin Index:** A lower index signifies a better partitioning. It is the average 'similarity' between clusters, where similarity is a measure that compares the distance between clusters with the size of the clusters themselves.
                    - **Calinski-Harabasz Index:** Also known as the Variance Ratio Criterion, a higher index relates to a model with better defined clusters.
                """)

            # Display statistics for each cluster in separate columns
            cols = st.columns(num_clusters)
            max_num_cars = 0
            for i in range(num_clusters):
                cluster_data = df_roll[df_roll['Cluster'] == i]
                max_num_cars = max(max_num_cars, cluster_data.shape[0])

            for i in range(num_clusters):
                cluster_data = df_roll[df_roll['Cluster'] == i]
                with cols[i]:
                    st.write(f'Cluster {i+1}')
                    cluster_data_column = cluster_data[selected_columns]
                    # Compute statistics using Pandas describe method
                    st.dataframe(cluster_data_column.describe().transpose())

                    # Obtain and display car type data
                    car_types = cluster_data.index.unique()
                    car_types_df = pd.DataFrame(car_types, columns=['Car Type'])
                    # Ensure the table has an equal number of rows
                    car_types_df = car_types_df.reindex(np.arange(max_num_cars)).fillna('')
                    st.dataframe(car_types_df)  # Display car type table

                    # Plotting
                    for selected_column in selected_columns:
                        # Fit a normal distribution to the cluster data
                        cluster_data_clean = cluster_data[selected_column].dropna()  # Ensure no NaN values
                        mu, std = norm.fit(cluster_data_clean)
                        plt.hist(cluster_data_clean, bins=30, density=True, alpha=0.6, color='g')
                        xmin, xmax = plt.xlim()
                        x = np.linspace(xmin, xmax, 100)
                        p = norm.pdf(x, mu, std)
                        plt.plot(x, p, 'k', linewidth=2)
                        plt.title(f'Normal Distribution for {selected_column}')
                        st.pyplot(plt)
                        plt.clf()  # Clear the figure for the next plot


                        with st.expander("Show Parameters"):
                            st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                            st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                            st.write("""
                                - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                                - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                                - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                                - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                            """)

def function3():
    st.write(" Executed> ğŸ‘©â€ğŸ’»**Database Version:** Lateral Force Test: V0")

    # åŠ è½½æ•°æ®å¹¶è¿›è¡Œè½¬ç½®
    @st.cache_data
    def load_data():
        data = pd.read_csv('knc_Lateral_data_v01.csv')
        # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯åˆ—åï¼Œç¬¬ä¸€åˆ—æ˜¯è½¦å‹ï¼Œè¿›è¡Œè½¬ç½®
        data = data.set_index(data.columns[0]).transpose()
        return data
    

    df_lat = load_data()


    # åœ¨ Streamlit ä¸­æ˜¾ç¤ºæ–‡ä»¶å
    filename = 'knc_Lateral_data_v01.csv'
    st.write("Loaded Filename:")
    st.text(filename)

    # ä½¿ç”¨ multiselect é€‰æ‹©è¦åˆ†æçš„åˆ—
    selected_columns = st.multiselect('Select the columns for analysis:', df_lat.columns)

    # é€‰æ‹©åˆ†æç±»å‹
    analysis_type = st.radio(
        "Select the analysis type:",
        ('Normal Distribution Fit', 'K-means Clustering')
    )

    # æ ¹æ®é€‰æ‹©è¿›è¡Œåˆ†æ
    if analysis_type == 'Normal Distribution Fit':
        for selected_column in selected_columns:
            # å¯¹é€‰å®šçš„åˆ—è¿›è¡Œæ­£æ€åˆ†å¸ƒæ‹Ÿåˆ
            data = df_lat[selected_column].dropna()
            mu, std = norm.fit(data)
            
            # æ¯ä¸ªåˆ—éƒ½æ–°å»ºä¸€ä¸ªå›¾å½¢
            fig, ax = plt.subplots()
            ax.hist(data, bins=30, density=True, alpha=0.6, color='g')
            xmin, xmax = ax.get_xlim()
            x = np.linspace(xmin, xmax, 100)
            p = norm.pdf(x, mu, std)
            ax.plot(x, p, 'k', linewidth=2)
            ax.set_title(f'Normal Distribution Fit for {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Density')
            
            # æ˜¾ç¤ºå›¾å½¢
            st.pyplot(fig)
            
            # å…³é—­å›¾å½¢ä»¥é¿å…é‡å 
            plt.close(fig)

            with st.expander("Show Parameters"):
                st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                st.write("""
                    - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                    - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                    - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                    - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                """)

    elif analysis_type == 'K-means Clustering':
        # é€‰æ‹©è¦åˆ›å»ºçš„èšç±»æ•°
        num_clusters = st.slider('Select number of clusters:', min_value=2, max_value=10, value=3)

        if st.button('Perform K-means Clustering'):
            
            # Prepare the data by dropping NaNs and storing it for clustering
            data_for_clustering = df_lat[selected_columns].dropna()

            # Perform K-means Clustering
            kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data_for_clustering)

            # Create a new DataFrame for the cluster labels with the same index as the data used for clustering
            labels_df = pd.DataFrame(kmeans.labels_, index=data_for_clustering.index, columns=['Cluster'])

            # Join the cluster labels to the original DataFrame
            df_lat = df_lat.join(labels_df)

            # Compute the evaluation metrics
            silhouette_avg = silhouette_score(data_for_clustering, kmeans.labels_)
            davies_bouldin = davies_bouldin_score(data_for_clustering, kmeans.labels_)
            calinski_harabasz = calinski_harabasz_score(data_for_clustering, kmeans.labels_)
            # Display the evaluation metrics
            st.write(f"Silhouette Coefficient: {silhouette_avg}")
            st.write(f"Davies-Bouldin Index: {davies_bouldin}")
            st.write(f"Calinski-Harabasz Index: {calinski_harabasz}")
            # Expander for explanation of cluster evaluation metrics
            with st.expander("Explanation of Cluster Evaluation Metrics"):
                st.write("""
                    - **Silhouette Coefficient:** This metric ranges from -1 to 1. A high value indicates that objects are well matched to their own cluster and poorly matched to neighboring clusters.
                    - **Davies-Bouldin Index:** A lower index signifies a better partitioning. It is the average 'similarity' between clusters, where similarity is a measure that compares the distance between clusters with the size of the clusters themselves.
                    - **Calinski-Harabasz Index:** Also known as the Variance Ratio Criterion, a higher index relates to a model with better defined clusters.
                """)

            # Display statistics for each cluster in separate columns
            cols = st.columns(num_clusters)
            max_num_cars = 0
            for i in range(num_clusters):
                cluster_data = df_lat[df_lat['Cluster'] == i]
                max_num_cars = max(max_num_cars, cluster_data.shape[0])

            for i in range(num_clusters):
                cluster_data = df_lat[df_lat['Cluster'] == i]
                with cols[i]:
                    st.write(f'Cluster {i+1}')
                    cluster_data_column = cluster_data[selected_columns]
                    # Compute statistics using Pandas describe method
                    st.dataframe(cluster_data_column.describe().transpose())

                    # Obtain and display car type data
                    car_types = cluster_data.index.unique()
                    car_types_df = pd.DataFrame(car_types, columns=['Car Type'])
                    # Ensure the table has an equal number of rows
                    car_types_df = car_types_df.reindex(np.arange(max_num_cars)).fillna('')
                    st.dataframe(car_types_df)  # Display car type table

                    # Plotting
                    for selected_column in selected_columns:
                        # Fit a normal distribution to the cluster data
                        cluster_data_clean = cluster_data[selected_column].dropna()  # Ensure no NaN values
                        mu, std = norm.fit(cluster_data_clean)
                        plt.hist(cluster_data_clean, bins=30, density=True, alpha=0.6, color='g')
                        xmin, xmax = plt.xlim()
                        x = np.linspace(xmin, xmax, 100)
                        p = norm.pdf(x, mu, std)
                        plt.plot(x, p, 'k', linewidth=2)
                        plt.title(f'Normal Distribution for {selected_column}')
                        st.pyplot(plt)
                        plt.clf()  # Clear the figure for the next plot


                        with st.expander("Show Parameters"):
                            st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                            st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                            st.write("""
                                - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                                - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                                - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                                - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                            """)    

def function4():
    st.write(" Executed> ğŸ‘©â€ğŸ’»**Database Version:** Longitudinal Force (Braking) Test: V0")

    # åŠ è½½æ•°æ®å¹¶è¿›è¡Œè½¬ç½®
    @st.cache_data
    def load_data():
        data = pd.read_csv('knc_Longitudinal_data_v01.csv')
        # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯åˆ—åï¼Œç¬¬ä¸€åˆ—æ˜¯è½¦å‹ï¼Œè¿›è¡Œè½¬ç½®
        data = data.set_index(data.columns[0]).transpose()
        return data
    

    df_long = load_data()


    # åœ¨ Streamlit ä¸­æ˜¾ç¤ºæ–‡ä»¶å
    filename = 'knc_Lateral_data_v01.csv'
    st.write("Loaded Filename:")
    st.text(filename)

    # ä½¿ç”¨ multiselect é€‰æ‹©è¦åˆ†æçš„åˆ—
    selected_columns = st.multiselect('Select the columns for analysis:', df_long.columns)

    # é€‰æ‹©åˆ†æç±»å‹
    analysis_type = st.radio(
        "Select the analysis type:",
        ('Normal Distribution Fit', 'K-means Clustering')
    )

    # æ ¹æ®é€‰æ‹©è¿›è¡Œåˆ†æ
    if analysis_type == 'Normal Distribution Fit':
        for selected_column in selected_columns:
            # å¯¹é€‰å®šçš„åˆ—è¿›è¡Œæ­£æ€åˆ†å¸ƒæ‹Ÿåˆ
            data = df_long[selected_column].dropna()
            mu, std = norm.fit(data)
            
            # æ¯ä¸ªåˆ—éƒ½æ–°å»ºä¸€ä¸ªå›¾å½¢
            fig, ax = plt.subplots()
            ax.hist(data, bins=30, density=True, alpha=0.6, color='g')
            xmin, xmax = ax.get_xlim()
            x = np.linspace(xmin, xmax, 100)
            p = norm.pdf(x, mu, std)
            ax.plot(x, p, 'k', linewidth=2)
            ax.set_title(f'Normal Distribution Fit for {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Density')
            
            # æ˜¾ç¤ºå›¾å½¢
            st.pyplot(fig)
            
            # å…³é—­å›¾å½¢ä»¥é¿å…é‡å 
            plt.close(fig)

            with st.expander("Show Parameters"):
                st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                st.write("""
                    - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                    - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                    - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                    - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                """)

    elif analysis_type == 'K-means Clustering':
        # é€‰æ‹©è¦åˆ›å»ºçš„èšç±»æ•°
        num_clusters = st.slider('Select number of clusters:', min_value=2, max_value=10, value=3)

        if st.button('Perform K-means Clustering'):
            
            # Prepare the data by dropping NaNs and storing it for clustering
            data_for_clustering = df_long[selected_columns].dropna()

            # Perform K-means Clustering
            kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data_for_clustering)

            # Create a new DataFrame for the cluster labels with the same index as the data used for clustering
            labels_df = pd.DataFrame(kmeans.labels_, index=data_for_clustering.index, columns=['Cluster'])

            # Join the cluster labels to the original DataFrame
            df_long = df_lat.join(labels_df)

            # Compute the evaluation metrics
            silhouette_avg = silhouette_score(data_for_clustering, kmeans.labels_)
            davies_bouldin = davies_bouldin_score(data_for_clustering, kmeans.labels_)
            calinski_harabasz = calinski_harabasz_score(data_for_clustering, kmeans.labels_)
            # Display the evaluation metrics
            st.write(f"Silhouette Coefficient: {silhouette_avg}")
            st.write(f"Davies-Bouldin Index: {davies_bouldin}")
            st.write(f"Calinski-Harabasz Index: {calinski_harabasz}")
            # Expander for explanation of cluster evaluation metrics
            with st.expander("Explanation of Cluster Evaluation Metrics"):
                st.write("""
                    - **Silhouette Coefficient:** This metric ranges from -1 to 1. A high value indicates that objects are well matched to their own cluster and poorly matched to neighboring clusters.
                    - **Davies-Bouldin Index:** A lower index signifies a better partitioning. It is the average 'similarity' between clusters, where similarity is a measure that compares the distance between clusters with the size of the clusters themselves.
                    - **Calinski-Harabasz Index:** Also known as the Variance Ratio Criterion, a higher index relates to a model with better defined clusters.
                """)

            # Display statistics for each cluster in separate columns
            cols = st.columns(num_clusters)
            max_num_cars = 0
            for i in range(num_clusters):
                cluster_data = df_long[df_long['Cluster'] == i]
                max_num_cars = max(max_num_cars, cluster_data.shape[0])

            for i in range(num_clusters):
                cluster_data = df_long[df_long['Cluster'] == i]
                with cols[i]:
                    st.write(f'Cluster {i+1}')
                    cluster_data_column = cluster_data[selected_columns]
                    # Compute statistics using Pandas describe method
                    st.dataframe(cluster_data_column.describe().transpose())

                    # Obtain and display car type data
                    car_types = cluster_data.index.unique()
                    car_types_df = pd.DataFrame(car_types, columns=['Car Type'])
                    # Ensure the table has an equal number of rows
                    car_types_df = car_types_df.reindex(np.arange(max_num_cars)).fillna('')
                    st.dataframe(car_types_df)  # Display car type table

                    # Plotting
                    for selected_column in selected_columns:
                        # Fit a normal distribution to the cluster data
                        cluster_data_clean = cluster_data[selected_column].dropna()  # Ensure no NaN values
                        mu, std = norm.fit(cluster_data_clean)
                        plt.hist(cluster_data_clean, bins=30, density=True, alpha=0.6, color='g')
                        xmin, xmax = plt.xlim()
                        x = np.linspace(xmin, xmax, 100)
                        p = norm.pdf(x, mu, std)
                        plt.plot(x, p, 'k', linewidth=2)
                        plt.title(f'Normal Distribution for {selected_column}')
                        st.pyplot(plt)
                        plt.clf()  # Clear the figure for the next plot


                        with st.expander("Show Parameters"):
                            st.write(f"**Mean (Âµ):** The average or central value of the dataset for `{selected_column}` is {mu:.2f}.")
                            st.write(f"**Standard Deviation (Ïƒ):** Measures the amount of variation or dispersion of the dataset for `{selected_column}` is {std:.2f}.")
                            st.write("""
                                - **Mean (Âµ):** The average or central value of a dataset, indicating its location.
                                - **Standard Deviation (Ïƒ):** The measure of variability or dispersion in a dataset, indicating spread.
                                - **Histogram:** A chart that displays the distribution of data, with each bar representing the frequency of data within a specific interval.
                                - **Density Plot:** This curve is an estimate of the data distribution, with its shape determined by the mean and standard deviation.
                            """)        

def function5():
    st.write(" Executed> ğŸ‘©â€ğŸ’»**Database Version:** Align Torque Test: V0")

# æ¨¡æ‹ŸåŠ è½½è¿‡ç¨‹çš„å‡½æ•°
def run_loading_animation():
    progress_bar = st.progress(0)
    for percent_complete in range(100):
        time.sleep(0.01)  # ç­‰å¾…æ—¶é—´å¯ä»¥è°ƒæ•´
        progress_bar.progress(percent_complete + 1)
    progress_bar.empty()  # åŠ è½½å®Œæˆåæ¸…é™¤è¿›åº¦æ¡

# åˆ›å»ºç½‘é¡µ
st.title('KnC Database Analysis')

# æ˜¾ç¤ºä¸€è¡Œæ–‡å­—
st.write('Welcome to the KnC Database Analysis page.')

# æ˜¾ç¤ºå¯ä»¥æŠ˜å çš„å†…å®¹
with st.expander("See explanation"):
    st.write("""
         This is some explanation of the analysis that can be hidden or shown.
         """)

# åˆ›å»ºä¸€ä¸ªSelectboxæ§ä»¶
option = st.selectbox(
    'Choose a function to execute',
    ('Choose a Test', 'Bump Test', 'Roll Test', 'Lateral Force Test', 'Longitudinal Force (Braking) Test', 'Align Torque Test')  # åˆå§‹ä¸ºç©ºé€‰é¡¹
)

# å½“ç”¨æˆ·é€‰æ‹©ä¸€ä¸ªé€‰é¡¹åï¼Œæ˜¾ç¤ºåŠ è½½åŠ¨ç”»ï¼Œç„¶åæ‰§è¡Œå¯¹åº”çš„å‡½æ•°
if option:
    # æ˜¾ç¤ºè¯»å–åŠ¨ç”»ï¼Œåˆ°100åå†æ‰§è¡Œå‡½æ•°
    run_loading_animation()

    # æ ¹æ®é€‰æ‹©æ‰§è¡Œä¸åŒçš„å‡½æ•°
    if option == 'Bump Test':
        function1()
    elif option == 'Roll Test':
        function2()
    elif option == 'Lateral Force Test':
        function3()
    elif option == 'Longitudinal Force (Braking) Test':
        function4()
    elif option == 'Align Torque Test':
        function5()
